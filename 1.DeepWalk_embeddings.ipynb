{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepWalk Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow==2.4.0 six~=1.15.0 joblib==0.14.0 numpy~=1.19.2\n",
    "# Install ge from git@github.com:shenweichen/GraphEmbedding.git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from ge import DeepWalk\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inoutpath = '/home/xiaopengxu/Desktop/data-covid-review/2021-05-11/'\n",
    "compdata_path = inoutpath + 'features.ori_doc2vec.csv'\n",
    "feature_path = inoutpath + 'features.ori_doc2vec_deepwalk.csv'\n",
    "num_walks = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and remove duplicate papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(compdata_path):\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f') + \": Loading data ...\")\n",
    "    papers = pd.read_csv(compdata_path, index_col=False)\n",
    "    papers.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    print(\"Count number of published papers in archives: \")\n",
    "    print(pd.notnull(papers.published).value_counts())\n",
    "\n",
    "    return papers\n",
    "\n",
    "def redup_papers(papers):\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f') + \": Remove duplicates ...\")\n",
    "    papers_redup = papers.drop_duplicates(subset=['title'])\n",
    "    print(\"Number of duplicated papers: {}\".format(len(papers) - len(papers_redup)))\n",
    "    return papers_redup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 13:47:59.109182: Loading data ...\n",
      "Count number of published papers in archives: \n",
      "False    14313\n",
      "True       779\n",
      "Name: published, dtype: int64\n",
      "2021-05-14 13:47:59.664823: Remove duplicates ...\n",
      "Number of duplicated papers: 329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaopengxu/anaconda3/envs/ml-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (4,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "papers = load_data(compdata_path)\n",
    "papers_redup = redup_papers(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get referencing edges\n",
    "\n",
    "Extract the paper referencing edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edgelist(papers_redup):\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f') + \": Generating edgelist ...\")\n",
    "    doi2ref = dict()  # dict of doi -> reference doi's\n",
    "    for idx in papers_redup.index:\n",
    "        doi2ref[papers_redup['p_doi'].loc[idx]] = papers_redup['ref'].loc[idx]\n",
    "\n",
    "    edge_list = list()  # list of doi -> ref doi\n",
    "    for k in doi2ref.keys():\n",
    "        if type(doi2ref[k]) is float:  ## handle nan values\n",
    "            continue\n",
    "\n",
    "        for val in doi2ref[k].split(', '):\n",
    "            if val == 'NA':  # ignore NA values of papers\n",
    "                continue\n",
    "            edge_list.append((k, val))\n",
    "\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 13:47:59.758205: Generating edgelist ...\n"
     ]
    }
   ],
   "source": [
    "edge_list = generate_edgelist(papers_redup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepWalk Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_get_embeddings(edge_list, papers, num_walks=2000, em_size=50):\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f') + \": Generating directed citation graph ...\")\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f') + \": Start training DeepWalk model ...\")\n",
    "\n",
    "    model = DeepWalk(G, walk_length=10, num_walks=num_walks, workers=10)\n",
    "    model.train(window_size=5, iter=5, workers=10, embed_size=em_size)\n",
    "\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f') + \": Get DeepWalk embeddings ...\")\n",
    "    embeddings = model.get_embeddings()\n",
    "\n",
    "    num_nodes = len(papers)\n",
    "    p_doi = papers['p_doi'].tolist()\n",
    "    DW_em = np.empty([num_nodes, em_size])\n",
    "    for i in range(num_nodes):\n",
    "        node = p_doi[i]\n",
    "        if node in embeddings.keys():\n",
    "            DW_em[i, :] = embeddings[node]\n",
    "\n",
    "    columns = ['dw ' + str(i + 1) for i in range(em_size)]\n",
    "    pd_deepwalk_features = pd.DataFrame(DW_em, columns=columns)\n",
    "\n",
    "    return pd_deepwalk_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 13:48:00.243287: Generating directed citation graph ...\n",
      "2021-05-14 13:48:01.318434: Start training DeepWalk model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n",
      "2021-05-14 15:48:53.543376: Get DeepWalk embeddings ...\n"
     ]
    }
   ],
   "source": [
    "pd_deepwalk_features = train_get_embeddings(edge_list, papers, num_walks=num_walks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine features and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(filepath, papers, pd_deepwalk_features):\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f') + \": Save features ...\")\n",
    "\n",
    "    papers.reset_index(drop=True, inplace=True)\n",
    "    pd_deepwalk_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    pd.concat([papers, pd_deepwalk_features], axis=1).to_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 15:49:18.279460: Save features ...\n"
     ]
    }
   ],
   "source": [
    "save_features(feature_path, papers, pd_deepwalk_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
